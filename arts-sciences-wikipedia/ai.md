# ai

tags #ai #sw

here we are

## New

https://www.ghostlystock.com/

https://dreamfusion3d.github.io/gallery.html
  * https://news.ycombinator.com/item?id=33025446
* https://news.ycombinator.com/item?id=33020181
* https://gorgeous.adityashankar.xyz/
  * https://news.ycombinator.com/item?id=33055340


## articles

With Stable Diffusion, you may never believe what you see online again
* https://arstechnica.com/information-technology/2022/09/with-stable-diffusion-you-may-never-believe-what-you-see-online-again/
* https://prompthero.com/

## Stable Diffusion

* https://constant.meiring.nz/playing/2022/08/04/playing-with-stable-diffusion.html
  * https://news.ycombinator.com/item?id=32710365
* https://metaphysic.ai/stable-diffusion-is-video-coming-soon/
* https://www.craiyon.com/
* https://news.ycombinator.com/item?id=32658408
* https://news.ycombinator.com/item?id=32634074
* https://news.ycombinator.com/item?id=32651556
* https://andys.page/posts/how-to-draw/
* https://replicate.com/andreasjansson/stable-diffusion-animation
* https://simonwillison.net/2022/Aug/29/stable-diffusion/
* https://stability.ai/
* https://thealgorithmicbridge.substack.com/p/stable-diffusion-is-the-most-important
* https://news.ycombinator.com/item?id=32631673
* https://jalammar.github.io/illustrated-stable-diffusion/

### hugging face

* https://huggingface.co/spaces/stabilityai/stable-diffusion

## NLP

* https://www.theatlantic.com/technology/archive/2022/09/artificial-intelligence-machine-learing-natural-language-processing/661401/


## reference

Artificial general intelligence

* https://en.wikipedia.org/wiki/Artificial_general_intelligence
> Artificial general intelligence (AGI) is the hypothetical ability of an intelligent agent to understand or learn any intellectual task that a human being can

https://en.wikipedia.org/wiki/Foundation_models

* A foundation model is a large artificial intelligence model trained on a vast quantity of unlabeled data at scale (usually by self-supervised learning) resulting in a model that can be adapted to a wide range of downstream tasks.
* Foundation models are behind a major transformation in how AI systems are built since their introduction in 2018.
* Early examples of foundation models were large pre-trained language models including BERT and GPT-3.
* Subsequently, several multimodal foundation models have been produced including DALL-E, Flamingo, and Florence.
* The Stanford Institute for Human-Centered Artificial Intelligence's (HAI) Center for Research on Foundation Models (CRFM) popularized the term.

https://hai.stanford.edu/news/introducing-center-research-foundation-models-crfm


## midjourney

* https://www.midjourney.com/app/
* https://midjourney.gitbook.io/docs/


## craiyon / dall-e mini

* https://news.ycombinator.com/item?id=31699841

## Open AI

* https://openai.com/dall-e-2/
* https://imagen.research.google/
* https://news.ycombinator.com/item?id=32589185
* https://news.ycombinator.com/item?id=32586439
* https://openart.ai/


## Fiction

It Looks Like You’re Trying To Take Over The World
* https://www.gwern.net/Clippy
>It might help to imagine a hard takeoff scenario using solely known sorts of NN & scaling effects… Below is a story which may help stretch your imagination and defamiliarize the 2022 state of machine learning.
>
>To read the annotated alternate version of this story, scroll to the end or manually disable ‘reader-mode’ (the book icons) in the theme toggle in the upper-right corner.

MIRI announces new "Death With Dignity" strategy
	#april-fools
* https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy
>tl;dr:  It's obvious at this point that humanity isn't going to solve the alignment problem, or even try very hard, or even go out with much of a fight.  Since survival is unattainable, we should shift the focus of our efforts to helping humanity die with with slightly more dignity.

## Smart People Talking

Yudkowsky Contra Christiano On AI Takeoff Speeds
* https://astralcodexten.substack.com/p/yudkowsky-contra-christiano-on-ai?s=r

>In 2008, thousands of blog readers - including yours truly, who had discovered the rationality community just a few months before - watched Robin Hanson debate Eliezer Yudkowsky on the future of AI.

Axis of Ordinary
* https://axisofordinary.substack.com/p/links-for-2022-04-04?s=r
> A polished version of gwern’s AI-takeover short-story: “It might help to imagine a hard takeoff scenario using solely known sorts of NN & scaling effects… Below is a story which may help stretch your imagination and defamiliarize the 2022 state of machine learning.” https://www.gwern.net/Clippy

Hacker News > AGI
* https://hn.algolia.com/?dateRange=all&page=0&prefix=false&query=agi&sort=byDate&type=story

Reddit
* https://www.reddit.com/r/agi/

## More

* https://news.ycombinator.com/item?id=30939282
	* https://spectrum.ieee.org/andrew-ng-data-centric-ai