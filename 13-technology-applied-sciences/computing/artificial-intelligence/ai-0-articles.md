# ai

tags #ai #sw

## News

## Publishers

* https://medium.com/mlearning-ai
* https://therundown.ai/
* https://www.futuretools.io/ ~ many tools
* https://www.futurepedia.io/


## articles

* 2023-03-17 ~ https://thenewstack.io/coding-sucks-anyway-matt-welsh-on-the-end-of-programming/
  * Product managers + AI will replace coders
* 2023-03-12 ~ https://minimaxir.com/
  * https://news.ycombinator.com/from?site=minimaxir.com
* 2022-12-14 ~ https://www.worksinprogress.co/issue/ai-from-superintelligence-to-chatgpt/
* 2023-02=10 ~ https://oneusefulthing.substack.com/p/a-quick-and-sobering-guide-to-cloning



## Smart People Talking


### Are Human Designers Becoming Obsolete

Why AI design is unstoppable.
CHRIS LÜDERS
>https://chrislueders.substack.com/p/are-human-designers-becoming-obsolete

Good responses with examples to many criticisms

### 2023-02

* https://news.ycombinator.com/item?id=30939282
	* https://spectrum.ieee.org/andrew-ng-data-centric-ai

### 2022-12-16 > The next decades might be wild

* https://www.lesswrong.com/posts/qRtD4WqKRYEtT5pi3/the-next-decades-might-be-wild

Yudkowsky Contra Christiano On AI Takeoff Speeds
* https://astralcodexten.substack.com/p/yudkowsky-contra-christiano-on-ai?s=r

>In 2008, thousands of blog readers - including yours truly, who had discovered the rationality community just a few months before - watched Robin Hanson debate Eliezer Yudkowsky on the future of AI.

Axis of Ordinary
* https://axisofordinary.substack.com/p/links-for-2022-04-04?s=r
> A polished version of gwern’s AI-takeover short-story: “It might help to imagine a hard takeoff scenario using solely known sorts of NN & scaling effects… Below is a story which may help stretch your imagination and defamiliarize the 2022 state of machine learning.” https://www.gwern.net/Clippy

Hacker News > AGI
* https://hn.algolia.com/?dateRange=all&page=0&prefix=false&query=agi&sort=byDate&type=story

Reddit
* https://www.reddit.com/r/agi/


### incredible things people are already doing with GPT-4

https://twitter.com/LinusEkenstam/status/1635754587775967233

## Fiction

It Looks Like You’re Trying To Take Over The World
* https://www.gwern.net/Clippy
>It might help to imagine a hard takeoff scenario using solely known sorts of NN & scaling effects… Below is a story which may help stretch your imagination and defamiliarize the 2022 state of machine learning.
>
>To read the annotated alternate version of this story, scroll to the end or manually disable ‘reader-mode’ (the book icons) in the theme toggle in the upper-right corner.

MIRI announces new "Death With Dignity" strategy #april-fools
* https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy
>tl;dr:  It's obvious at this point that humanity isn't going to solve the alignment problem, or even try very hard, or even go out with much of a fight.  Since survival is unattainable, we should shift the focus of our efforts to helping humanity die with with slightly more dignity.


## Games

### Dark Forest: This sci-fi blockchain game could help create a metaverse that no one owns
Dark Forest shows how advanced cryptography can be used in a game—and how blockchains might host decentralized digital worlds.
* https://www.technologyreview.com/2022/11/10/1062981/dark-forest-blockchain-video-game-creates-metaverse/
* https://twitter.com/darkforest_eth?lang=en
* https://blog.zkga.me/
