# AI FOOM / AGI

## Reference

* https://en.wiktionary.org/wiki/foom
* https://en.wikiquote.org/wiki/Eliezer_Yudkowsky


## Sources

### Hacker News > AGI
* https://hn.algolia.com/?dateRange=all&page=0&prefix=false&query=agi&sort=byDate&type=story

### Reddit
* https://www.reddit.com/r/agi/

## Writers

### Eliezer Yudkowsky

* https://www.lesswrong.com/users/eliezer_yudkowsky

### jacob_cannell

* https://www.lesswrong.com/users/jacob_cannell
* https://entersingularity.wordpress.com/


## 2023-05-07

## 2023-04-23

## Contra Yudkowsky on Doom from Foom #2

* https://www.lesswrong.com/posts/LF3DDZ67knxuyadbm/contra-yudkowsky-on-doom-from-foom-2


### Contra Yudkowsky on AI Doom

* https://www.lesswrong.com/posts/Lwy7XKsDEEkjskZ77/contra-yudkowsky-on-ai-doom


## 2023-03-17

* https://thenewstack.io/coding-sucks-anyway-matt-welsh-on-the-end-of-programming/
  * Product managers + AI will replace coders
* 2023-03-12 ~ https://minimaxir.com/
  * https://news.ycombinator.com/from?site=minimaxir.com
* 2022-12-14 ~ https://www.worksinprogress.co/issue/ai-from-superintelligence-to-chatgpt/
* 2023-02=10 ~ https://oneusefulthing.substack.com/p/a-quick-and-sobering-guide-to-cloning


### 2023-02

* https://news.ycombinator.com/item?id=30939282
  * https://spectrum.ieee.org/andrew-ng-data-centric-ai

## 2022-12-17

### Chris Lüders ~ Are Human Designers Becoming Obsolete

Why AI design is unstoppable.

* https://chrislueders.substack.com/p/are-human-designers-becoming-obsolete

Good responses with examples to many criticisms

### 2022-12-16 > The next decades might be wild

* https://www.lesswrong.com/posts/qRtD4WqKRYEtT5pi3/the-next-decades-might-be-wild

Yudkowsky Contra Christiano On AI Takeoff Speeds
* https://astralcodexten.substack.com/p/yudkowsky-contra-christiano-on-ai?s=r

>In 2008, thousands of blog readers - including yours truly, who had discovered the rationality community just a few months before - watched Robin Hanson debate Eliezer Yudkowsky on the future of AI.

### Axis of Ordinary
* https://axisofordinary.substack.com/p/links-for-2022-04-04?s=r
> A polished version of gwern’s AI-takeover short-story: “It might help to imagine a hard takeoff scenario using solely known sorts of NN & scaling effects… Below is a story which may help stretch your imagination and defamiliarize the 2022 state of machine learning.” https://www.gwern.net/Clippy


## 2017-08-04

### A Tentative Typology of AI-Foom Scenarios

* https://davidmanheim.medium.com/a-tentative-typology-of-ai-foom-scenarios-54ff20c906c3

